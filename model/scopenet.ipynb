{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1184f8ad-661a-4b1f-a063-15ca2054a645",
   "metadata": {},
   "source": [
    "Scopenet\n",
    "========\n",
    "\n",
    "Scopenet is a neural network model for enhancing microscopy images for certain types of specimens, such as blood or tissue biopsies, in such a way that they can be viewed without staining or inducing photo-toxicity. The project is inspired by the call to action in the Journal of Cell Science, [Harnessing artificial intelligence to reduce phototoxicity in live imaging](https://journals.biologists.com/jcs/article/137/3/jcs261545/342983/Harnessing-artificial-intelligence-to-reduce).\n",
    "\n",
    "In order to train this model, data was captured with an [OpenFlexure Microscope](https://openflexure.org/). We randomly select several different areas on a blood smear and select the center 256x256 rectangle. This portion of the frame is the one with the least amount of optical abberations. We then select the best focus and illumination. The stage control and illumination control is performed with the [Sangaboard](https://taulab.eu/openflexure/5-sangaboard-v5.html) attached to the microscope. We capture the frame and label it as the \"best\" frame. We then shift the X, Y and Z stage to cause the same 256x256 to appear elsewhere on the frame, where it is out of focus and with slightly reduced lighting. We then randomly change the illumination conditions (which includes the absence of illumination change) and capture a second shapshot. This gives us two 256x256 frames - one under ideal conditions and one that is blurry, noisy, and not well light. Scopenet is trained to predict the frame under ideal conditions from the one that is faulty.\n",
    "\n",
    "An existing dataset is hosted on Kaggle where it can be downloaded for free. You will need an account on Kaggle and a generated API token (which you can generate from your user settings). You can then place your key into `~/.kaggle/kaggle.json` (or `%HOMEPATH%/kaggle.json` on Windows). For more information on how to do this, visit [kagglehub's Github page](https://github.com/Kaggle/kagglehub?tab=readme-ov-file#option-3-read-credentials-from-kagglejson).\n",
    "\n",
    "Once that's done, you can train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369eea00-3df4-4336-ac33-06276c96bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(device='cuda:0', dataset_root='/home/tholbert/.cache/kagglehub/datasets/tay10r/scopenet/versions/1', batch_size=16, num_epochs=100)\n"
     ]
    }
   ],
   "source": [
    "from scopenet.config import open_config, Config\n",
    "\n",
    "# Open the user-defined configuration file.\n",
    "# It will use defaults if the config file does not exist.\n",
    "# This will also download the dataset if it hasn't already been done.\n",
    "config = open_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3693192-bb62-4141-892d-1668b89257ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (enc1): _Encoder(\n",
      "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (enc2): _Encoder(\n",
      "    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (enc3): _Encoder(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (enc4): _Encoder(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (enc5): _Encoder(\n",
      "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_blocks): Sequential(\n",
      "    (0): _ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): _ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): _ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec5): _Decoder(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dec4): _Decoder(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dec3): _Decoder(\n",
      "    (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dec2): _Decoder(\n",
      "    (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dec1): _Decoder(\n",
      "    (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (refine): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from scopenet.net import Net\n",
    "\n",
    "# Instantiate a blank model. This model is based on U-net, with added residual blocks in the bottleneck.\n",
    "net = Net(in_channels=3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2578ea-de42-40ff-a31d-600de9c7b2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 640, Test samples: 320\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scopenet.dataset import Dataset\n",
    "\n",
    "# Load the datasets. Each training sample is lazily loaded into memory.\n",
    "# Once it is in memory, it remains there in order to speed up training.\n",
    "# This means you may want to watch your system memory in case you don't have enough.\n",
    "train_data = Dataset(Path(config.dataset_root) / 'train')\n",
    "test_data = Dataset(Path(config.dataset_root) / 'test')\n",
    "print(f'Training samples: {len(train_data)}, Test samples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244ff62a-ee9f-4e94-b8ba-ef27f3fba9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Open the compute device you'll be using to train.\n",
    "device = torch.device(config.device)\n",
    "print(f'Torch Device: {device}')\n",
    "# Load the network onto that device.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613b55fe-89a3-4b3e-8791-d6fcbcc4eb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3408f5682a664004b48c496ee6698b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5870203094dc4c72b3d739313b621e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc96555b67a41029131981bc0213cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216f52c3e4754343bc038ef847542d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c92775322140de9d6623ee66342cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0098692d2944682833dfbf725ff1d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25092a915d446b7845ddbeb6ad7a7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ed1d2b78a74951a6273f7154d3c0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5c1ccc32e9434db336ec4f800e27f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa10bbd13b747e19e3be8ea9a2744f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scopenet.train import TrainingSession\n",
    "from scopenet.ssim import SSIMLoss\n",
    "\n",
    "# Instantiate a training session.\n",
    "# This will optimize the model and run test it every epoch.\n",
    "# We use SSIM loss instead of MSE, since it captures differences in focus better\n",
    "session = TrainingSession(train_data,\n",
    "                          test_data,\n",
    "                          device=device,\n",
    "                          model_name='scopenet',\n",
    "                          batch_size=config.batch_size,\n",
    "                          in_jupyter=True)\n",
    "session.run_epochs(net, loss_fn=SSIMLoss(), num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2e09f-7de7-4859-b629-301902c10203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
